<div class="project-header">
    <h1>NLP Research Paper Summarizer</h1>
    <div class="tags">
        <span class="tag">Natural Language Processing</span>
        <span class="tag">Transformers</span>
        <span class="tag">BERT</span>
        <span class="tag">Python</span>
        <span class="tag">Hugging Face</span>
    </div>
</div>

<img src="imgs/project_placeholder.jpg" alt="NLP Research Paper Summarizer" class="project-image-full">

<div class="project-description">
    <p>
        This project involves developing a transformer-based model to automatically summarize machine learning 
        research papers, extracting key findings and methodologies. The system helps researchers quickly grasp 
        the essential information from scientific papers, saving time and improving research efficiency.
    </p>
</div>

<div class="project-section">
    <h2>Project Overview</h2>
    <p>
        The exponential growth in scientific publications makes it increasingly difficult for researchers to 
        stay updated with the latest developments. Automatic summarization of research papers can significantly 
        reduce the time needed to extract key information from scientific literature.
    </p>
    <p>
        In this project, I developed a specialized transformer-based model for summarizing machine learning 
        research papers. The system is designed to identify and extract the most important contributions, 
        methodologies, and results from papers, presenting them in a concise and coherent summary.
    </p>
</div>

<div class="project-section">
    <h2>Key Features</h2>
    <ul>
        <li>Specialized model for scientific paper summarization</li>
        <li>Section-aware summarization (abstract, methods, results, etc.)</li>
        <li>Extraction of key findings and contributions</li>
        <li>Handling of mathematical notation and technical terminology</li>
        <li>Support for PDF input format</li>
        <li>Web interface for easy access</li>
    </ul>
</div>

<div class="project-section">
    <h2>Technical Details</h2>
    <p>
        The project is built using the Hugging Face Transformers library and fine-tuned BERT models. The 
        implementation includes:
    </p>
    <ul>
        <li>PDF parsing and preprocessing for scientific papers</li>
        <li>Fine-tuning of transformer models on a corpus of ML papers</li>
        <li>Section classification for structured summarization</li>
        <li>Extractive and abstractive summarization components</li>
        <li>Evaluation using ROUGE and human assessment</li>
        <li>Flask-based web application for deployment</li>
    </ul>
</div>

<div class="project-section">
    <h2>Results</h2>
    <p>
        The system achieves a ROUGE-L score of 0.42 on a test set of machine learning papers, outperforming 
        general-purpose summarization models by a significant margin. User studies show that researchers save 
        an average of 45 minutes per paper when using the summarizer, with 87% reporting that the summaries 
        accurately captured the key information from the papers.
    </p>
</div>

<div class="project-links">
    <a href="https://github.com/FredCarvalhoOliveira/paper-summarizer" target="_blank">
        <i class="fab fa-github"></i> View on GitHub
    </a>
    <a href="#" target="_blank">
        <i class="fas fa-external-link-alt"></i> Live Demo
    </a>
</div> 